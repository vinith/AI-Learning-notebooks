{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "armed-vegetation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "import idx2numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import random as rand\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "x_digit = idx2numpy.convert_from_file('data/train-images-idx3-ubyte')\n",
    "y_digit = idx2numpy.convert_from_file('data/train-labels-idx1-ubyte')\n",
    "\n",
    "print(x_digit.shape, y_digit.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "disciplinary-oriental",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 56, 28) (100000, 2) (10000, 56, 28) (10000, 2)\n"
     ]
    }
   ],
   "source": [
    "### Generate train and test data using mnist set with NUM_SIZE digits\n",
    "NUM_SIZE = 2\n",
    "\n",
    "image_dict = [[] for i in range(10)]\n",
    "for digit,image in zip(y_digit, x_digit):\n",
    "    image_dict[digit].append(image)\n",
    "\n",
    "\n",
    "def gen_test_data(num_data):\n",
    "    x_data, y_data = np.zeros((num_data, NUM_SIZE, 28, 28)), np.zeros((num_data, NUM_SIZE))\n",
    "    for i in range(num_data):\n",
    "        for k in range(NUM_SIZE):\n",
    "            rand_digit = rand.randint(0,9)\n",
    "            rand_img = rand.choice(image_dict[rand_digit])\n",
    "            y_data[i,k] = rand_digit\n",
    "            x_data[i,k] = rand_img\n",
    "    return x_data.reshape(num_data, NUM_SIZE * 28, -1), y_data\n",
    "\n",
    "x_train, y_train = gen_test_data(100000)\n",
    "x_test, y_test = gen_test_data(10000)\n",
    "x_test_check = x_test\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "juvenile-engine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1568, 100000) (20, 100000) (1568, 10000) (20, 10000)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.T.reshape(-1, 100000)\n",
    "x_test = x_test.T.reshape(-1,10000)\n",
    "y_test = tf.one_hot(y_test, 10).numpy().reshape(10000,-1).T\n",
    "y_train = tf.one_hot(y_train, 10).numpy().reshape(100000,-1).T\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "print(type(x_train), type(x_test), type(y_train), type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "concrete-chance",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims = [x_train.shape[0], 512, 10 * NUM_SIZE]\n",
    "\n",
    "def init_params():\n",
    "    weights = {}\n",
    "    biases = {}\n",
    "    for l in range(1, len(layer_dims)):\n",
    "        weights[l] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01;\n",
    "        biases[l] = np.zeros((layer_dims[l],1))\n",
    "    return weights,biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "generous-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "# 20 x m input\n",
    "def softmax(z):\n",
    "    return tf.nn.softmax(z.reshape(2,10,-1), axis=1).numpy().reshape(20,-1)\n",
    "    \n",
    "\n",
    "#  20 x m vs 20 x m\n",
    "def compute_cost(Y_expected, Y_actual):\n",
    "    #print(\"\\nExpected \\n\",Y_expected)\n",
    "    #print(\"\\n Actual \", Y_actual)\n",
    "    m = Y_expected.shape[1]\n",
    "    return -2/m * np.sum(np.multiply(Y_expected, np.log(Y_actual)))\n",
    "\n",
    "def forward_prop(X, W, B):\n",
    "    Z = {}\n",
    "    A = {0: X}\n",
    "    cost = 0\n",
    "    for l in range (1, len(layer_dims)):\n",
    "        Z[l] = np.dot(W[l] , A[l-1]) + B[l]\n",
    "        if l == len(layer_dims) -1:\n",
    "            A[l] = softmax(Z[l])\n",
    "        else:\n",
    "            A[l] = relu(Z[l])\n",
    "    return Z, A\n",
    "\n",
    "def calc_accuracy(Y_expected, Y_actual):\n",
    "    Y_actual = Y_actual.astype(int)\n",
    "    Y_expected = Y_expected.astype(int)\n",
    "    return 0.5 * np.sum(np.bitwise_and(Y_expected, Y_actual))/Y_expected.shape[1]\n",
    "\n",
    "def backward_prop_update_weights(Z, A, Y, W, B, learning_rate):\n",
    "    m = Y.shape[1]\n",
    "    #derivation flowing into the activation function (starts with 1 because dL/dL = 1)\n",
    "    propogated_derv = 1\n",
    "    activation_derv = 0\n",
    "    \n",
    "    for l in range(len(layer_dims) -1, 0 , -1):\n",
    "        if l == len(layer_dims)-1:\n",
    "            ##softmax derivative (Y_actual - Y_expected)\n",
    "            activation_derv = A[l] - Y\n",
    "        else:\n",
    "            ##relu derivative\n",
    "            activation_derv = (Z[l] > 0) * 1\n",
    "            \n",
    "        dZ = np.multiply(propogated_derv, activation_derv)\n",
    "        dW = 1/m * np.dot(dZ, A[l-1].T)\n",
    "        dB = 1/m * (np.sum(dZ,axis=1, keepdims=True))\n",
    "        W[l] = W[l] - learning_rate * dW\n",
    "        B[l] = B[l] - learning_rate * dB\n",
    "        propogated_derv = np.dot(W[l].T, dZ)\n",
    "    return W, B\n",
    "\n",
    "def train(X, Y, numitrs, learning_rate, batch_size):\n",
    "    W, B = init_params()\n",
    "    for itrs in range(numitrs):\n",
    "        print(itrs)\n",
    "        for batch in range(X.shape[1]//batch_size):\n",
    "            #print(\"Processing batch \" + str(batch*batch_size) + \" to \" + str((batch+1) * batch_size))\n",
    "            bx = X[:, batch*batch_size: (batch + 1) * batch_size]\n",
    "            by = Y[:, batch*batch_size: (batch + 1) * batch_size]\n",
    "            Z, A = forward_prop(bx, W, B)\n",
    "            W, B = backward_prop_update_weights(Z , A, by, W, B, learning_rate)\n",
    "        l = len(layer_dims) -1\n",
    "        cost = compute_cost(by, A[l])\n",
    "        accuracy = calc_accuracy(by, (A[l] > 0.5) * 1)\n",
    "        print(\"Cost :\" + str(cost) + \" Accuracy: \" + str(accuracy))\n",
    "    return W, B\n",
    "\n",
    "def predict(X, W, B):\n",
    "    Z, A = forward_prop(X, W, B)\n",
    "    return A[len(layer_dims)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "immune-commonwealth",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Cost :3.1129281393535573 Accuracy: 0.756\n",
      "1\n",
      "Cost :2.3535912709282174 Accuracy: 0.813\n",
      "2\n",
      "Cost :2.018581999075305 Accuracy: 0.832\n",
      "3\n",
      "Cost :1.815822956959441 Accuracy: 0.853\n",
      "4\n",
      "Cost :1.6743570921096476 Accuracy: 0.864\n",
      "5\n",
      "Cost :1.5677146400698538 Accuracy: 0.873\n",
      "6\n",
      "Cost :1.4825376966287829 Accuracy: 0.882\n",
      "7\n",
      "Cost :1.4117979300092371 Accuracy: 0.882\n",
      "8\n",
      "Cost :1.351450905116181 Accuracy: 0.885\n",
      "9\n",
      "Cost :1.2986748506580834 Accuracy: 0.889\n",
      "10\n",
      "Cost :1.2519552700980463 Accuracy: 0.89\n",
      "11\n",
      "Cost :1.2103099993750734 Accuracy: 0.891\n",
      "12\n",
      "Cost :1.1730397297279338 Accuracy: 0.894\n",
      "13\n",
      "Cost :1.1392416116574944 Accuracy: 0.897\n",
      "14\n",
      "Cost :1.1080820000263758 Accuracy: 0.9\n",
      "15\n",
      "Cost :1.0788830678633758 Accuracy: 0.901\n",
      "16\n",
      "Cost :1.0514345660734015 Accuracy: 0.904\n",
      "17\n",
      "Cost :1.0255792787185491 Accuracy: 0.907\n",
      "18\n",
      "Cost :1.001272228405463 Accuracy: 0.907\n",
      "19\n",
      "Cost :0.9781687378445699 Accuracy: 0.908\n",
      "20\n",
      "Cost :0.9561203398592304 Accuracy: 0.91\n",
      "21\n",
      "Cost :0.9356337265883863 Accuracy: 0.911\n",
      "22\n",
      "Cost :0.9160057488762393 Accuracy: 0.911\n",
      "23\n",
      "Cost :0.8971208442100292 Accuracy: 0.912\n",
      "24\n",
      "Cost :0.8792749084955901 Accuracy: 0.914\n",
      "25\n",
      "Cost :0.86209598587367 Accuracy: 0.917\n",
      "26\n",
      "Cost :0.8455410237974622 Accuracy: 0.92\n",
      "27\n",
      "Cost :0.8296194426081336 Accuracy: 0.921\n",
      "28\n",
      "Cost :0.8142641501164023 Accuracy: 0.923\n",
      "29\n",
      "Cost :0.7995870651803811 Accuracy: 0.925\n",
      "30\n",
      "Cost :0.7853511430899339 Accuracy: 0.927\n",
      "31\n",
      "Cost :0.7716804504428235 Accuracy: 0.927\n",
      "32\n",
      "Cost :0.7584754096069437 Accuracy: 0.93\n",
      "33\n",
      "Cost :0.7457415533721715 Accuracy: 0.931\n",
      "34\n",
      "Cost :0.7334181041997732 Accuracy: 0.932\n",
      "35\n",
      "Cost :0.7213886640485175 Accuracy: 0.933\n",
      "36\n",
      "Cost :0.7097568365002799 Accuracy: 0.933\n",
      "37\n",
      "Cost :0.6986757308391723 Accuracy: 0.933\n",
      "38\n",
      "Cost :0.6879480005885505 Accuracy: 0.936\n",
      "39\n",
      "Cost :0.6774637701894355 Accuracy: 0.937\n",
      "40\n",
      "Cost :0.6671528292688312 Accuracy: 0.938\n",
      "41\n",
      "Cost :0.6572329953170774 Accuracy: 0.938\n",
      "42\n",
      "Cost :0.6476280081923498 Accuracy: 0.938\n",
      "43\n",
      "Cost :0.6382702747039893 Accuracy: 0.939\n",
      "44\n",
      "Cost :0.6290232226178959 Accuracy: 0.939\n",
      "45\n",
      "Cost :0.6202273417046955 Accuracy: 0.94\n",
      "46\n",
      "Cost :0.6116958715609885 Accuracy: 0.94\n",
      "47\n",
      "Cost :0.6032768592555116 Accuracy: 0.94\n",
      "48\n",
      "Cost :0.5951481266497822 Accuracy: 0.941\n",
      "49\n",
      "Cost :0.5870955305274204 Accuracy: 0.942\n",
      "50\n",
      "Cost :0.5793796818882825 Accuracy: 0.942\n",
      "51\n",
      "Cost :0.5718168706709371 Accuracy: 0.942\n",
      "52\n",
      "Cost :0.564466554383464 Accuracy: 0.942\n",
      "53\n",
      "Cost :0.5572005770350426 Accuracy: 0.943\n",
      "54\n",
      "Cost :0.5501096403151077 Accuracy: 0.943\n",
      "55\n",
      "Cost :0.5433390845700545 Accuracy: 0.945\n",
      "56\n",
      "Cost :0.5367051878086988 Accuracy: 0.946\n",
      "57\n",
      "Cost :0.5301922900185991 Accuracy: 0.949\n",
      "58\n",
      "Cost :0.5236774371464354 Accuracy: 0.95\n",
      "59\n",
      "Cost :0.5173427375033107 Accuracy: 0.95\n",
      "60\n",
      "Cost :0.5111618372771273 Accuracy: 0.951\n",
      "61\n",
      "Cost :0.5050826502517657 Accuracy: 0.952\n",
      "62\n",
      "Cost :0.4992652760158104 Accuracy: 0.952\n",
      "63\n",
      "Cost :0.49357012020337504 Accuracy: 0.953\n",
      "64\n",
      "Cost :0.4879984047363721 Accuracy: 0.953\n",
      "65\n",
      "Cost :0.48250643776155094 Accuracy: 0.953\n",
      "66\n",
      "Cost :0.47712718444361485 Accuracy: 0.953\n",
      "67\n",
      "Cost :0.4717900529772908 Accuracy: 0.954\n",
      "68\n",
      "Cost :0.46657115125388476 Accuracy: 0.954\n",
      "69\n",
      "Cost :0.46147177605180606 Accuracy: 0.955\n",
      "70\n",
      "Cost :0.45645229192779396 Accuracy: 0.955\n",
      "71\n",
      "Cost :0.45151588539325704 Accuracy: 0.956\n",
      "72\n",
      "Cost :0.4466548018089518 Accuracy: 0.957\n",
      "73\n",
      "Cost :0.44189538398383993 Accuracy: 0.957\n",
      "74\n",
      "Cost :0.4372966913372682 Accuracy: 0.957\n",
      "75\n",
      "Cost :0.4328521183813257 Accuracy: 0.958\n",
      "76\n",
      "Cost :0.4284140719174407 Accuracy: 0.959\n",
      "77\n",
      "Cost :0.4240671855542912 Accuracy: 0.96\n",
      "78\n",
      "Cost :0.4197744411259161 Accuracy: 0.96\n",
      "79\n",
      "Cost :0.4155855143516376 Accuracy: 0.96\n",
      "80\n",
      "Cost :0.4114041916760317 Accuracy: 0.96\n",
      "81\n",
      "Cost :0.40718236331685415 Accuracy: 0.961\n",
      "82\n",
      "Cost :0.40307426425973375 Accuracy: 0.961\n",
      "83\n",
      "Cost :0.39900702893292006 Accuracy: 0.961\n",
      "84\n",
      "Cost :0.3950535936977975 Accuracy: 0.962\n",
      "85\n",
      "Cost :0.3911182111827731 Accuracy: 0.962\n",
      "86\n",
      "Cost :0.38723911162649155 Accuracy: 0.962\n",
      "87\n",
      "Cost :0.3833885155107909 Accuracy: 0.962\n",
      "88\n",
      "Cost :0.3796288521767614 Accuracy: 0.963\n",
      "89\n",
      "Cost :0.37595403726140547 Accuracy: 0.964\n",
      "90\n",
      "Cost :0.37232538747017346 Accuracy: 0.964\n",
      "91\n",
      "Cost :0.36875236720911087 Accuracy: 0.965\n",
      "92\n",
      "Cost :0.36532321087098163 Accuracy: 0.967\n",
      "93\n",
      "Cost :0.36190972231269536 Accuracy: 0.968\n",
      "94\n",
      "Cost :0.3586526689169763 Accuracy: 0.968\n",
      "95\n",
      "Cost :0.3553089654520545 Accuracy: 0.969\n",
      "96\n",
      "Cost :0.3521029740342781 Accuracy: 0.97\n",
      "97\n",
      "Cost :0.34884621258867593 Accuracy: 0.97\n",
      "98\n",
      "Cost :0.3456908182120526 Accuracy: 0.971\n",
      "99\n",
      "Cost :0.3425499889119501 Accuracy: 0.971\n"
     ]
    }
   ],
   "source": [
    "W , B = train(x_train, y_train, 100, 0.00009, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "incident-burton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is 0.9466\n"
     ]
    }
   ],
   "source": [
    "output = predict(x_test, W, B)\n",
    "print(\"Accuracy on test set is \" + str(calc_accuracy(y_test, (output > 0.5) * 1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "passive-walter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]]\n",
      "(5000, 56, 28)\n",
      "(56, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x30f9b10d0>"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print((output[:,100:101] > 0.5) * 1.0)\n",
    "test = x_test_check[100:101,:,:].reshape(56,-1)\n",
    "print(test.shape)\n",
    "plt.imshow(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-waterproof",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-signature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p38TF",
   "language": "python",
   "name": "p38tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
