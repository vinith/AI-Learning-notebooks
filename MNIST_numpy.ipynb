{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "duplicate-pierre",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000) (784, 10000) (10, 60000) (10, 10000)\n"
     ]
    }
   ],
   "source": [
    "import idx2numpy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "x_train = idx2numpy.convert_from_file('data/train-images-idx3-ubyte').T.reshape(-1,60000)\n",
    "y_train = idx2numpy.convert_from_file('data/train-labels-idx1-ubyte').reshape(-1,1).T\n",
    "\n",
    "x_test = idx2numpy.convert_from_file('data/t10k-images-idx3-ubyte').T.reshape(-1,10000)\n",
    "y_test = idx2numpy.convert_from_file('data/t10k-labels-idx1-ubyte').reshape(-1,1).T\n",
    "\n",
    "y_train = tf.one_hot(y_train, 10, axis=1).numpy().reshape(10,-1)\n",
    "y_test = tf.one_hot(y_test, 10, axis=1).numpy().reshape(10,-1)\n",
    "\n",
    "x_train, x_test = x_train / 255.0, x_test/255.0\n",
    "\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "offshore-investment",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_dims = [x_train.shape[0], 512, 10]\n",
    "\n",
    "def init_params():\n",
    "    weights = {}\n",
    "    biases = {}\n",
    "    for l in range(1, len(layer_dims)):\n",
    "        weights[l] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01;\n",
    "        biases[l] = np.zeros((layer_dims[l],1))\n",
    "    return weights,biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "informational-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return np.maximum(0,z)\n",
    "\n",
    "# 10 x m input\n",
    "def softmax(z):\n",
    "    exp = np.exp(z)\n",
    "    return exp/np.sum(exp, axis=0)\n",
    "\n",
    "# 10 x m vs 10 x m\n",
    "def compute_cost(Y_expected, Y_actual):\n",
    "    m = Y_expected.shape[1]\n",
    "    return -1/m * np.sum(np.multiply(Y_expected, np.log(Y_actual)))\n",
    "\n",
    "def forward_prop(X, W, B):\n",
    "    Z = {}\n",
    "    A = {0: X}\n",
    "    cost = 0\n",
    "    for l in range (1, len(layer_dims)):\n",
    "        Z[l] = np.dot(W[l] , A[l-1]) + B[l]\n",
    "        if l == len(layer_dims) -1:\n",
    "            A[l] = softmax(Z[l])\n",
    "        else:\n",
    "            A[l] = relu(Z[l])\n",
    "    return Z, A\n",
    "\n",
    "def calc_accuracy(Y_expected, Y_actual):\n",
    "    #print(Y_actual.shape)\n",
    "    #print(Y_actual[:,:30])\n",
    "    Y_actual = Y_actual.astype(int)\n",
    "    Y_expected = Y_expected.astype(int)\n",
    "    return 1.0 * np.sum(np.bitwise_and(Y_expected, Y_actual))/Y_expected.shape[1]\n",
    "\n",
    "def backward_prop_update_weights(Z, A, Y, W, B, learning_rate):\n",
    "    m = Y.shape[1]\n",
    "    #derivation flowing into the activation function (starts with 1 because dL/dL = 1)\n",
    "    propogated_derv = 1\n",
    "    activation_derv = 0\n",
    "    \n",
    "    for l in range(len(layer_dims) -1, 0 , -1):\n",
    "        if l == len(layer_dims)-1:\n",
    "            ##softmax derivative (Y_actual - Y_expected)\n",
    "            activation_derv = A[l] - Y\n",
    "        else:\n",
    "            ##relu derivative\n",
    "            activation_derv = (Z[l] > 0) * 1\n",
    "            \n",
    "        dZ = np.multiply(propogated_derv, activation_derv)\n",
    "        dW = 1/m * np.dot(dZ, A[l-1].T)\n",
    "        dB = 1/m * (np.sum(dZ,axis=1, keepdims=True))\n",
    "        W[l] = W[l] - learning_rate * dW\n",
    "        B[l] = B[l] - learning_rate * dB\n",
    "        propogated_derv = np.dot(W[l].T, dZ)\n",
    "    return W, B\n",
    "\n",
    "def train(X, Y, numitrs, learning_rate):\n",
    "    W, B = init_params()\n",
    "    for itrs in range(numitrs):\n",
    "        Z, A = forward_prop(X, W, B)\n",
    "        W, B = backward_prop_update_weights(Z , A, Y, W, B, learning_rate)\n",
    "        #print(itrs)\n",
    "        if itrs % 50 == 0:\n",
    "            print(itrs)\n",
    "            l = len(layer_dims) -1\n",
    "            cost = compute_cost(Y, A[l])\n",
    "            #print(\"output : \", A[l][:,:10])\n",
    "            accuracy = calc_accuracy(Y, (A[l] > 0.5) * 1)\n",
    "            print(\"Cost :\" + str(cost) + \" Accuracy: \" + str(accuracy))\n",
    "    return W, B\n",
    "\n",
    "def predict(X, W, B):\n",
    "    Z, A = forward_prop(X, W, B)\n",
    "    return A[len(layer_dims)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "current-thomson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Cost :2.302595236436559 Accuracy: 0.0\n",
      "50\n",
      "Cost :2.3016482461140035 Accuracy: 0.0\n",
      "100\n",
      "Cost :2.3010941713232587 Accuracy: 0.0\n",
      "150\n",
      "Cost :2.3006226441237008 Accuracy: 0.0\n",
      "200\n",
      "Cost :2.2999716138544333 Accuracy: 0.0\n",
      "250\n",
      "Cost :2.298621231221195 Accuracy: 0.0\n",
      "300\n",
      "Cost :2.2946044235920398 Accuracy: 0.0\n",
      "350\n",
      "Cost :2.27361432303316 Accuracy: 0.0\n",
      "400\n",
      "Cost :2.1355566632863883 Accuracy: 0.009466666666666667\n",
      "450\n",
      "Cost :1.9316166446652532 Accuracy: 0.047\n",
      "500\n",
      "Cost :1.617798209618591 Accuracy: 0.055483333333333336\n",
      "550\n",
      "Cost :1.2861195417544513 Accuracy: 0.18006666666666668\n",
      "600\n",
      "Cost :1.0428794681843452 Accuracy: 0.3081333333333333\n",
      "650\n",
      "Cost :0.7839691525063048 Accuracy: 0.5739666666666666\n",
      "700\n",
      "Cost :0.6814834049717768 Accuracy: 0.687\n",
      "750\n",
      "Cost :0.6339939534324646 Accuracy: 0.7329833333333333\n",
      "800\n",
      "Cost :0.6033976191098546 Accuracy: 0.7576666666666667\n",
      "850\n",
      "Cost :0.5799389874438813 Accuracy: 0.7743\n",
      "900\n",
      "Cost :0.5600572789418025 Accuracy: 0.7869833333333334\n",
      "950\n",
      "Cost :0.5418749728810147 Accuracy: 0.7967833333333333\n",
      "1000\n",
      "Cost :0.5252080830662839 Accuracy: 0.8050333333333334\n",
      "1050\n",
      "Cost :0.5098141256813906 Accuracy: 0.8130833333333334\n",
      "1100\n",
      "Cost :0.4950742606724881 Accuracy: 0.81985\n",
      "1150\n",
      "Cost :0.4804776530710366 Accuracy: 0.8262666666666667\n",
      "1200\n",
      "Cost :0.4654832920015357 Accuracy: 0.8324333333333334\n",
      "1250\n",
      "Cost :0.4494063426210458 Accuracy: 0.8384666666666667\n",
      "1300\n",
      "Cost :0.43170885231385914 Accuracy: 0.8450333333333333\n",
      "1350\n",
      "Cost :0.41240397894972075 Accuracy: 0.8522833333333333\n",
      "1400\n",
      "Cost :0.3923542167593562 Accuracy: 0.8600166666666667\n",
      "1450\n",
      "Cost :0.3731026382353424 Accuracy: 0.8677166666666667\n",
      "1500\n",
      "Cost :0.35584522239382194 Accuracy: 0.8743166666666666\n",
      "1550\n",
      "Cost :0.34078029020347805 Accuracy: 0.8800833333333333\n",
      "1600\n",
      "Cost :0.3275185104829025 Accuracy: 0.8850333333333333\n",
      "1650\n",
      "Cost :0.3156581693823963 Accuracy: 0.88925\n",
      "1700\n",
      "Cost :0.30485799556912135 Accuracy: 0.8927666666666667\n",
      "1750\n",
      "Cost :0.29489425424319915 Accuracy: 0.8965166666666666\n",
      "1800\n",
      "Cost :0.2855495776244309 Accuracy: 0.8996833333333333\n",
      "1850\n",
      "Cost :0.2767777886530762 Accuracy: 0.9030666666666667\n",
      "1900\n",
      "Cost :0.2685287402399773 Accuracy: 0.9060833333333334\n",
      "1950\n",
      "Cost :0.2607001965512279 Accuracy: 0.9094833333333333\n",
      "2000\n",
      "Cost :0.2532722575919107 Accuracy: 0.9122333333333333\n",
      "2050\n",
      "Cost :0.24622859317992102 Accuracy: 0.9146\n",
      "2100\n",
      "Cost :0.2395183126256531 Accuracy: 0.9167333333333333\n",
      "2150\n",
      "Cost :0.23312138631183577 Accuracy: 0.9190666666666667\n",
      "2200\n",
      "Cost :0.22705511412805088 Accuracy: 0.9214333333333333\n",
      "2250\n",
      "Cost :0.22129138023292652 Accuracy: 0.9235666666666666\n",
      "2300\n",
      "Cost :0.2158010402273246 Accuracy: 0.9255666666666666\n",
      "2350\n",
      "Cost :0.21056807318635687 Accuracy: 0.92725\n",
      "2400\n",
      "Cost :0.20559140263286485 Accuracy: 0.929\n",
      "2450\n",
      "Cost :0.20085574966615685 Accuracy: 0.93075\n",
      "2500\n",
      "Cost :0.19635011104234912 Accuracy: 0.9324166666666667\n",
      "2550\n",
      "Cost :0.19203377079168632 Accuracy: 0.9340166666666667\n",
      "2600\n",
      "Cost :0.18791491661744814 Accuracy: 0.9355166666666667\n",
      "2650\n",
      "Cost :0.18399415893265397 Accuracy: 0.9368166666666666\n",
      "2700\n",
      "Cost :0.18025194667003205 Accuracy: 0.93795\n",
      "2750\n",
      "Cost :0.17667200518024098 Accuracy: 0.9391\n",
      "2800\n",
      "Cost :0.173254495304985 Accuracy: 0.9405166666666667\n",
      "2850\n",
      "Cost :0.16997691986029484 Accuracy: 0.9416\n",
      "2900\n",
      "Cost :0.1668236903829046 Accuracy: 0.9428166666666666\n",
      "2950\n",
      "Cost :0.16378234552114232 Accuracy: 0.9438166666666666\n"
     ]
    }
   ],
   "source": [
    "W , B = train(x_train, y_train, 3000, 0.08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "attached-monitoring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is 0.9422\n"
     ]
    }
   ],
   "source": [
    "output = predict(x_test, W, B)\n",
    "print(\"Accuracy on test set is \" + str(calc_accuracy(y_test, (output > 0.5) * 1.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "preceding-footwear",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10000)\n",
      "[[0 0 0 1 0]\n",
      " [0 0 1 0 0]\n",
      " [0 1 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 1]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [1 0 0 0 0]\n",
      " [0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(output.shape)\n",
    "a = (output[:,:5] > 0.5) * 1\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "south-seven",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7, 2, 1, 0, 4]], dtype=uint8)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_op = idx2numpy.convert_from_file('data/t10k-labels-idx1-ubyte').reshape(-1,1).T\n",
    "\n",
    "y_op[:,:5]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p38TF",
   "language": "python",
   "name": "p38tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
